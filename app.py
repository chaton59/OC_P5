#!/usr/bin/env python3
"""
Interface Gradio pour tester le mod√®le Employee Turnover en production.

D√©ploiement sur Hugging Face Spaces pour tests rapides.
Version de d√©monstration - Interface compl√®te en d√©veloppement.
"""
from pathlib import Path

import gradio as gr
import mlflow
import mlflow.pyfunc
from huggingface_hub import hf_hub_download

# Configuration
HF_MODEL_REPO = "ASI-Engineer/employee-turnover-model"
FALLBACK_RUN_ID = "40e43c8e425345bab3d19f27eb8fe5d8"


def load_model():
    """
    Charge le mod√®le depuis Hugging Face Hub (prod) ou MLflow local (dev).

    Ordre de priorit√©:
    1. HF Hub (mod√®le d√©ploy√© en production)
    2. MLflow local (d√©veloppement local)
    """
    # Essayer HF Hub en premier (production)
    try:
        # Download model from HF Hub
        model_path = hf_hub_download(
            repo_id=HF_MODEL_REPO, filename="model/model.pkl", repo_type="model"
        )
        model = mlflow.pyfunc.load_model(str(Path(model_path).parent))  # type: ignore[attr-defined]
        print(f"‚úÖ Mod√®le charg√© depuis HF Hub: {HF_MODEL_REPO}")
        return model, "HF Hub"
    except Exception as e:
        print(f"‚ö†Ô∏è HF Hub non disponible: {e}")

    # Fallback: MLflow local (d√©veloppement)
    mlflow.set_tracking_uri("sqlite:///mlflow.db")
    try:
        # Essayer Model Registry d'abord
        model = mlflow.pyfunc.load_model("models:/XGBoost_Employee_Turnover/latest")  # type: ignore[attr-defined]
        print("‚úÖ Mod√®le charg√© depuis MLflow Model Registry")
        return model, "MLflow Registry"
    except Exception:
        try:
            # Fallback sur run ID
            model = mlflow.pyfunc.load_model(f"runs:/{FALLBACK_RUN_ID}/model")  # type: ignore[attr-defined]
            print(f"‚úÖ Mod√®le charg√© depuis MLflow run: {FALLBACK_RUN_ID}")
            return model, "MLflow Local"
        except Exception as e2:
            print(f"‚ùå Erreur chargement MLflow: {e2}")
            return None, "Error"


# Charger le mod√®le au d√©marrage
try:
    model, model_source = load_model()
    MODEL_LOADED = model is not None
except Exception as e:
    print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
    MODEL_LOADED = False
    model = None
    model_source = "Error"


def get_model_info():
    """Retourne les informations sur le mod√®le."""
    if not MODEL_LOADED:
        return {
            "status": "‚ùå Mod√®le non disponible",
            "error": "Le mod√®le n'a pas pu √™tre charg√©",
            "solution": "V√©rifiez que le mod√®le est bien enregistr√© sur HF Hub ou entra√Æn√© localement",
        }

    try:
        info = {
            "status": "‚úÖ Mod√®le charg√© avec succ√®s",
            "source": model_source,
            "model_type": type(model).__name__,
            "features": "~50 features (apr√®s preprocessing)",
            "algorithme": "XGBoost + SMOTE",
            "hf_hub_repo": HF_MODEL_REPO if model_source == "HF Hub" else "N/A",
        }

        # Si MLflow local, ajouter les m√©triques
        if model_source == "MLflow Local":
            mlflow.set_tracking_uri("sqlite:///mlflow.db")
            client = mlflow.MlflowClient()
            runs = client.search_runs(
                experiment_ids=["1"], order_by=["start_time DESC"], max_results=1
            )
            if runs:
                run = runs[0]
                metrics = run.data.metrics
                info.update(
                    {
                        "run_id": run.info.run_id[:8],
                        "f1_score": f"{metrics.get('f1_score', 0):.4f}",
                        "accuracy": f"{metrics.get('accuracy', 0):.4f}",
                    }
                )

        info["info"] = "Interface de pr√©diction en d√©veloppement - API FastAPI √† venir"
        return info

    except Exception as e:
        return {"status": "‚úÖ Mod√®le charg√© (info limit√©es)", "error": str(e)}


# Interface Gradio
with gr.Blocks(  # type: ignore[attr-defined]
    title="Employee Turnover Prediction - DEV", theme=gr.themes.Soft()  # type: ignore[attr-defined]
) as demo:
    gr.Markdown("# üéØ Pr√©diction du Turnover - Employee Attrition")  # type: ignore[attr-defined]
    gr.Markdown("## Environment DEV - Test de d√©ploiement CI/CD")  # type: ignore[attr-defined]

    gr.Markdown(  # type: ignore[attr-defined]
        """
    ### üìä Statut du projet

    Ce Space est synchronis√© automatiquement depuis GitHub (branche `dev`).

    **Actuellement disponible :**
    - ‚úÖ Pipeline d'entra√Ænement MLflow complet (`main.py`)
    - ‚úÖ D√©ploiement automatique CI/CD (GitHub Actions ‚Üí HF Spaces)
    - ‚úÖ Tests unitaires et linting automatis√©s

    **En d√©veloppement :**
    - üöß Interface de pr√©diction interactive
    - üöß API FastAPI avec endpoints de pr√©diction
    - üöß Int√©gration PostgreSQL pour tracking des pr√©dictions
    """
    )

    with gr.Row():  # type: ignore[attr-defined]
        with gr.Column():  # type: ignore[attr-defined]
            gr.Markdown("### üîç Informations sur le mod√®le")  # type: ignore[attr-defined]
            check_btn = gr.Button("üìä V√©rifier le statut du mod√®le", variant="primary")  # type: ignore[attr-defined]

        with gr.Column():  # type: ignore[attr-defined]
            model_output = gr.JSON(label="Statut")  # type: ignore[attr-defined]

    check_btn.click(fn=get_model_info, inputs=[], outputs=model_output)

    gr.Markdown("---")  # type: ignore[attr-defined]

    gr.Markdown(  # type: ignore[attr-defined]
        """
    ### üõ†Ô∏è Prochaines √©tapes (selon etapes.txt)

    1. **√âtape 3** : D√©veloppement API FastAPI
       - Endpoints de pr√©diction avec validation Pydantic
       - Chargement dynamique des preprocessing artifacts (scaler, encoders)
       - Documentation Swagger/OpenAPI automatique

    2. **√âtape 4** : Int√©gration PostgreSQL
       - Stockage des inputs/outputs des pr√©dictions
       - Tra√ßabilit√© compl√®te des requ√™tes

    3. **√âtape 5** : Tests unitaires et fonctionnels
       - Tests des endpoints API
       - Tests de charge et performance
       - Couverture de code avec pytest-cov

    ### üìö Documentation
    - **Repository GitHub** : [chaton59/OC_P5](https://github.com/chaton59/OC_P5)
    - **MLflow Tracking** : Disponible en local (`./scripts/start_mlflow.sh`)
    - **M√©triques** : F1-Score optimis√©, gestion classes d√©s√©quilibr√©es (SMOTE)
    """
    )


if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
