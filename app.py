#!/usr/bin/env python3
"""
Interface Gradio pour tester le mod√®le Employee Turnover en production.

D√©ploiement sur Hugging Face Spaces pour tests rapides.
Version de d√©monstration - Interface compl√®te en d√©veloppement.
"""
import gradio as gr
import mlflow
import mlflow.sklearn


# Configuration MLflow
mlflow.set_tracking_uri("sqlite:///mlflow.db")

# Charger le mod√®le le plus r√©cent
MODEL_URI = "models:/Employee_Turnover_Model/latest"
# Fallback: utiliser un run_id sp√©cifique si le mod√®le n'est pas enregistr√©
FALLBACK_RUN_ID = "2dd66b2b125646e19cf123c6944c9185"


def load_model():
    """Charge le mod√®le depuis MLflow."""
    try:
        model = mlflow.sklearn.load_model(MODEL_URI)
        print(f"‚úÖ Mod√®le charg√© depuis Model Registry: {MODEL_URI}")
        return model
    except Exception as e:
        print(f"‚ö†Ô∏è Model Registry non disponible, utilisation du run_id: {e}")
        try:
            model = mlflow.sklearn.load_model(f"runs:/{FALLBACK_RUN_ID}/model")
            print(f"‚úÖ Mod√®le charg√© depuis run_id: {FALLBACK_RUN_ID}")
            return model
        except Exception as e2:
            print(f"‚ùå Erreur lors du chargement du mod√®le: {e2}")
            return None


# Charger le mod√®le au d√©marrage
try:
    model = load_model()
    MODEL_LOADED = model is not None
except Exception as e:
    print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
    MODEL_LOADED = False
    model = None


def get_model_info():
    """Retourne les informations sur le mod√®le."""
    if not MODEL_LOADED:
        return {
            "status": "‚ùå Mod√®le non disponible",
            "error": "Le mod√®le n'a pas pu √™tre charg√© depuis MLflow",
            "solution": "V√©rifiez que main.py a bien √©t√© ex√©cut√© pour entra√Æner le mod√®le",
        }

    try:
        # Obtenir des informations sur le mod√®le
        client = mlflow.MlflowClient()
        runs = client.search_runs(
            experiment_ids=["1"], order_by=["start_time DESC"], max_results=1
        )

        if runs:
            run = runs[0]
            metrics = run.data.metrics
            return {
                "status": "‚úÖ Mod√®le charg√© avec succ√®s",
                "run_id": run.info.run_id[:8],
                "f1_score": f"{metrics.get('f1_score', 0):.4f}",
                "accuracy": f"{metrics.get('accuracy', 0):.4f}",
                "features": "~50 features (apr√®s preprocessing)",
                "algorithme": "XGBoost + SMOTE",
                "info": "Interface de pr√©diction en d√©veloppement - API FastAPI √† venir",
            }
        else:
            return {
                "status": "‚úÖ Mod√®le charg√©",
                "info": "Pas de m√©triques disponibles",
                "run_id": FALLBACK_RUN_ID[:8],
            }

    except Exception as e:
        return {"status": "‚úÖ Mod√®le charg√© (info limit√©es)", "error": str(e)}


# Interface Gradio
with gr.Blocks(
    title="Employee Turnover Prediction - DEV", theme=gr.themes.Soft()
) as demo:
    gr.Markdown("# üéØ Pr√©diction du Turnover - Employee Attrition")
    gr.Markdown("## Environment DEV - Test de d√©ploiement CI/CD")

    gr.Markdown(
        """
    ### üìä Statut du projet
    
    Ce Space est synchronis√© automatiquement depuis GitHub (branche `dev`).
    
    **Actuellement disponible :**
    - ‚úÖ Pipeline d'entra√Ænement MLflow complet (`main.py`)
    - ‚úÖ D√©ploiement automatique CI/CD (GitHub Actions ‚Üí HF Spaces)
    - ‚úÖ Tests unitaires et linting automatis√©s
    
    **En d√©veloppement :**
    - üöß Interface de pr√©diction interactive
    - üöß API FastAPI avec endpoints de pr√©diction
    - üöß Int√©gration PostgreSQL pour tracking des pr√©dictions
    """
    )

    with gr.Row():
        with gr.Column():
            gr.Markdown("### üîç Informations sur le mod√®le")
            check_btn = gr.Button("üìä V√©rifier le statut du mod√®le", variant="primary")

        with gr.Column():
            model_output = gr.JSON(label="Statut")

    check_btn.click(fn=get_model_info, inputs=[], outputs=model_output)

    gr.Markdown("---")

    gr.Markdown(
        """
    ### üõ†Ô∏è Prochaines √©tapes (selon etapes.txt)
    
    1. **√âtape 3** : D√©veloppement API FastAPI
       - Endpoints de pr√©diction avec validation Pydantic
       - Chargement dynamique des preprocessing artifacts (scaler, encoders)
       - Documentation Swagger/OpenAPI automatique
    
    2. **√âtape 4** : Int√©gration PostgreSQL
       - Stockage des inputs/outputs des pr√©dictions
       - Tra√ßabilit√© compl√®te des requ√™tes
    
    3. **√âtape 5** : Tests unitaires et fonctionnels
       - Tests des endpoints API
       - Tests de charge et performance
       - Couverture de code avec pytest-cov
    
    ### üìö Documentation
    - **Repository GitHub** : [chaton59/OC_P5](https://github.com/chaton59/OC_P5)
    - **MLflow Tracking** : Disponible en local (`./scripts/start_mlflow.sh`)
    - **M√©triques** : F1-Score optimis√©, gestion classes d√©s√©quilibr√©es (SMOTE)
    """
    )


if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
