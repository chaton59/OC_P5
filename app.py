#!/usr/bin/env python3
"""
API FastAPI pour le mod√®le Employee Turnover.

Cette API expose le mod√®le de pr√©diction de d√©part des employ√©s avec :
- Validation stricte des inputs via Pydantic
- Preprocessing automatique
- Health check pour monitoring
- Documentation OpenAPI/Swagger automatique
"""
from contextlib import asynccontextmanager

from fastapi import Depends, FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware

from src.auth import verify_api_key
from src.config import get_settings
from src.models import get_model_info, load_model
from src.preprocessing import preprocess_for_prediction
from src.schemas import EmployeeInput, HealthCheck, PredictionOutput

# Charger la configuration
settings = get_settings()
API_VERSION = settings.API_VERSION


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Gestion du cycle de vie de l'application.

    Charge le mod√®le au d√©marrage et le garde en cache.
    """
    print("üöÄ D√©marrage de l'API Employee Turnover...")
    try:
        # Pr√©-charger le mod√®le au d√©marrage
        load_model()
        print("‚úÖ Mod√®le charg√© avec succ√®s")
    except Exception as e:
        print(f"‚ö†Ô∏è Avertissement : Le mod√®le n'a pas pu √™tre charg√© : {e}")

    yield  # L'application tourne

    print("üõë Arr√™t de l'API")


# Cr√©er l'application FastAPI
app = FastAPI(
    title="Employee Turnover Prediction API",
    description="API de pr√©diction du turnover des employ√©s avec XGBoost + SMOTE",
    version=API_VERSION,
    lifespan=lifespan,
    docs_url="/docs",
    redoc_url="/redoc",
)

# Configurer CORS (autoriser tous les domaines en dev)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/", tags=["Root"])
async def root():
    """
    Endpoint racine avec informations sur l'API.
    """
    return {
        "message": "Employee Turnover Prediction API",
        "version": API_VERSION,
        "docs": "/docs",
        "health": "/health",
        "predict": "/predict (POST)",
    }


@app.get("/health", response_model=HealthCheck, tags=["Monitoring"])
async def health_check():
    """
    Health check endpoint pour monitoring.

    V√©rifie que l'API est op√©rationnelle et que le mod√®le est charg√©.

    Returns:
        HealthCheck: Status de l'API et du mod√®le.

    Raises:
        HTTPException: 503 si le mod√®le n'est pas disponible.
    """
    try:
        model_info = get_model_info()

        return HealthCheck(
            status="healthy",
            model_loaded=model_info.get("cached", False),
            model_type=model_info.get("model_type", "Unknown"),
            version=API_VERSION,
        )
    except Exception as e:
        raise HTTPException(
            status_code=503,
            detail={
                "status": "unhealthy",
                "error": "Model not available",
                "message": str(e),
            },
        )


@app.post(
    "/predict",
    response_model=PredictionOutput,
    tags=["Prediction"],
    dependencies=[Depends(verify_api_key)] if settings.is_api_key_required else [],
)
async def predict(employee: EmployeeInput):
    """
    Endpoint de pr√©diction du turnover d'un employ√©.

    **PROT√âG√â PAR API KEY** : Requiert le header `X-API-Key` en production.

    Prend en entr√©e les donn√©es d'un employ√©, applique le preprocessing
    et retourne la pr√©diction avec les probabilit√©s.

    Args:
        employee: Donn√©es de l'employ√© valid√©es par Pydantic.

    Returns:
        PredictionOutput: Pr√©diction et probabilit√©s.

    Raises:
        HTTPException: 401 si API key invalide ou manquante.
        HTTPException: 500 si erreur lors de la pr√©diction.

    Examples:
        ```bash
        # Avec authentification
        curl -X POST http://localhost:8000/predict \\
          -H "X-API-Key: your-secret-key" \\
          -H "Content-Type: application/json" \\
          -d '{...}'
        ```
    """
    try:
        # 1. Charger le mod√®le
        model = load_model()

        # 2. Pr√©processing
        X = preprocess_for_prediction(employee)

        # 3. Pr√©diction
        prediction = int(model.predict(X)[0])

        # 4. Probabilit√©s (si le mod√®le supporte predict_proba)
        try:
            probabilities = model.predict_proba(X)[0]
            prob_0 = float(probabilities[0])
            prob_1 = float(probabilities[1])
        except AttributeError:
            # Si le mod√®le ne supporte pas predict_proba
            prob_0 = 1.0 if prediction == 0 else 0.0
            prob_1 = 1.0 if prediction == 1 else 0.0

        # 5. Niveau de risque
        if prob_1 < 0.3:
            risk_level = "Low"
        elif prob_1 < 0.7:
            risk_level = "Medium"
        else:
            risk_level = "High"

        return PredictionOutput(
            prediction=prediction,
            probability_0=prob_0,
            probability_1=prob_1,
            risk_level=risk_level,
        )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": "Prediction failed",
                "message": str(e),
                "solution": "V√©rifiez que les donn√©es sont correctes et que le mod√®le est disponible",
            },
        )


if __name__ == "__main__":
    import uvicorn

    print("üöÄ Lancement de l'API en mode d√©veloppement...")
    print("üìñ Documentation : http://localhost:8000/docs")

    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info",
    )
