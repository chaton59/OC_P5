---
title: Employee Turnover Prediction API
emoji: ğŸš€
colorFrom: blue
colorTo: green
sdk: gradio
sdk_version: "5.9.1"
app_file: app.py
pinned: false
---

<div align="center">

# ğŸš€ Employee Turnover Prediction API

[![Python Version](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.14-009688.svg)](https://fastapi.tiangolo.com)
[![Code Coverage](https://img.shields.io/badge/coverage-70.26%25-yellow.svg)](htmlcov/index.html)
[![Tests](https://img.shields.io/badge/tests-97%20passed-success.svg)](tests/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

**API REST de prÃ©diction du turnover des employÃ©s basÃ©e sur Machine Learning (XGBoost + SMOTE)**

[ğŸ”— Demo Production](https://asi-engineer-oc-p5.hf.space) Â· [ğŸ“š Documentation](docs/) Â· [ğŸ› Report Bug](https://github.com/chaton59/OC_P5/issues) Â· [ğŸ’¡ Request Feature](https://github.com/chaton59/OC_P5/issues)

</div>

---

## ğŸ“‹ Table des MatiÃ¨res

- [Ã€ Propos du Projet](#-Ã -propos-du-projet)
- [Architecture](#-architecture)
- [Choix Techniques](#-choix-techniques)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [DÃ©ploiement](#-dÃ©ploiement)
- [Mise Ã  Jour](#-mise-Ã -jour)
- [Tests](#-tests)
- [Documentation](#-documentation)
- [Changelog](#-changelog)
- [Auteurs](#-auteurs)
- [Licence](#-licence)

> **Note**: Les dÃ©pendances complÃ¨tes (transitives) sont listÃ©es dans [`requirements_dev.txt`](requirements_dev.txt) pour installation de dÃ©veloppement complet.

---

## ğŸ“Š Ã€ Propos du Projet

### Vue d'ensemble

Ce projet dÃ©ploie un **modÃ¨le de Machine Learning** en production via une **API REST moderne** pour prÃ©dire le risque de dÃ©part des employÃ©s d'une entreprise. DÃ©veloppÃ© dans le cadre du projet OpenClassrooms P5 "DÃ©ployez votre modÃ¨le de Machine Learning", il illustre les **meilleures pratiques** d'ingÃ©nierie logicielle et de MLOps.

### ProblÃ©matique

Les entreprises perdent des talents clÃ©s sans pouvoir anticiper. Ce modÃ¨le prÃ©dit le **risque de turnover** (probabilitÃ© qu'un employÃ© quitte l'entreprise) Ã  partir de 29 variables RH (satisfaction, salaire, anciennetÃ©, etc.).

### Solution

API REST performante exposant un modÃ¨le **XGBoost optimisÃ©** avec :
- âœ… **Validation robuste** des donnÃ©es via Pydantic
- âœ… **PrÃ©dictions en temps rÃ©el** (<2s) ou par batch (CSV)
- âœ… **TraÃ§abilitÃ© complÃ¨te** via PostgreSQL et logs JSON
- âœ… **Monitoring** et health checks intÃ©grÃ©s
- âœ… **CI/CD automatisÃ©** avec GitHub Actions
- âœ… **DÃ©ploiement cloud** sur HuggingFace Spaces

### Performances du ModÃ¨le

| MÃ©trique | Valeur | InterprÃ©tation |
|----------|--------|----------------|
| **F1 Score** | 0.85 | Excellent Ã©quilibre prÃ©cision/recall |
| **Recall** | 0.88 | DÃ©tecte 88% des dÃ©parts rÃ©els |
| **Precision** | 0.82 | 82% des prÃ©dictions "dÃ©part" sont correctes |
| **ROC AUC** | 0.91 | Excellente capacitÃ© de discrimination |



### FonctionnalitÃ©s ClÃ©s


- ğŸ”® **PrÃ©diction unitaire** : PrÃ©dit le risque pour un employÃ© (JSON)
- ğŸ“¦ **PrÃ©diction batch** : Traite des fichiers CSV complets (1000+ employÃ©s)
- ğŸ” **Authentification** : API Key sÃ©curisÃ©e (production)
- ğŸ›¡ï¸ **Rate limiting** : 20 req/min pour Ã©viter les abus
- ğŸ“Š **Monitoring** : Health check et logs structurÃ©s JSON
- ğŸ¨ **Interface Gradio** : UI web pour tests interactifs
- ğŸ“š **Documentation auto** : Swagger UI et ReDoc intÃ©grÃ©s
- ğŸ—„ï¸ **TraÃ§abilitÃ©** : Toutes les prÃ©dictions enregistrÃ©es en base PostgreSQL

**Version actuelle** : 3.2.1 | **DerniÃ¨re mise Ã  jour** : Janvier 2026

---

## ğŸ—ï¸ Architecture

### Vue d'ensemble High-Level

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLIENT     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   API REST   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  BASE DE     â”‚
â”‚              â”‚  JSON   â”‚   (FastAPI)  â”‚  SQL    â”‚  DONNÃ‰ES     â”‚
â”‚  â€¢ curl      â”‚         â”‚              â”‚         â”‚ (PostgreSQL) â”‚
â”‚  â€¢ Python    â”‚         â”‚  â€¢ Validationâ”‚         â”‚              â”‚
â”‚  â€¢ JS        â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â€¢ Authent.  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  â€¢ dataset   â”‚
â”‚  â€¢ Postman   â”‚  200 OK â”‚  â€¢ Logging   â”‚  SELECT â”‚  â€¢ ml_logs   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   MODÃˆLE ML  â”‚
                         â”‚  (XGBoost +  â”‚
                         â”‚    SMOTE)    â”‚
                         â”‚              â”‚
                         â”‚ HF Hub Cache â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline de PrÃ©diction

```
DonnÃ©es brutes
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. VALIDATION      â”‚  Pydantic vÃ©rifie types, contraintes, Ã©numÃ©rations
â”‚     (Pydantic)      â”‚  â†’ Rejette donnÃ©es invalides (HTTP 422)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. PREPROCESSING   â”‚  â€¢ Feature engineering (ratios, moyennes)
â”‚     (StandardScaler)â”‚  â€¢ OneHot encoding (catÃ©gorielles non-ordonnÃ©es)
â”‚                     â”‚  â€¢ Ordinal encoding (frÃ©quence dÃ©placements)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ Scaling (StandardScaler)
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PRÃ‰DICTION      â”‚  XGBoost prÃ©dit classe (0/1) + probabilitÃ©s
â”‚     (XGBoost)       â”‚  â€¢ 0 = Reste dans l'entreprise
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ 1 = Va quitter l'entreprise
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. POST-TRAITEMENT â”‚  â€¢ Calcul niveau de risque (Low/Medium/High)
â”‚     (API)           â”‚  â€¢ Enregistrement en DB (ml_logs)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ Logging structurÃ© JSON
          â”‚
          â–¼
    RÃ©ponse JSON
```

### Structure du Projet

```
OC_P5/
â”œâ”€â”€ api.py                      # ğŸšª Point d'entrÃ©e FastAPI principal
â”œâ”€â”€ app.py                      # ğŸ¨ Point d'entrÃ©e Gradio (HF Spaces)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ auth.py                 # ğŸ” Authentification API Key
â”‚   â”œâ”€â”€ config.py               # âš™ï¸ Configuration centralisÃ©e (.env)
â”‚   â”œâ”€â”€ logger.py               # ğŸ“ Logging structurÃ© JSON
â”‚   â”œâ”€â”€ models.py               # ğŸ¤– Chargement modÃ¨le depuis HuggingFace Hub
â”‚   â”œâ”€â”€ preprocessing.py        # ğŸ”§ Pipeline de preprocessing
â”‚   â”œâ”€â”€ rate_limit.py           # ğŸ›¡ï¸ Rate limiting (SlowAPI)
â”‚   â”œâ”€â”€ schemas.py              # âœ… Validation Pydantic (29 champs)
â”‚   â””â”€â”€ gradio_ui.py            # ğŸ¨ Interface Gradio web
â”œâ”€â”€ tests/                      # âœ… Suite de tests (97 tests, 70% coverage)
â”‚   â”œâ”€â”€ test_api_auth.py        # Tests authentification
â”‚   â”œâ”€â”€ test_api_predict.py     # Tests prÃ©dictions
â”‚   â”œâ”€â”€ test_api_validation.py  # Tests validation Pydantic
â”‚   â”œâ”€â”€ test_database.py        # Tests PostgreSQL
â”‚   â””â”€â”€ test_model.py           # Tests modÃ¨le ML
â”œâ”€â”€ ml_model/                   # ğŸ“ Scripts d'entraÃ®nement
â”‚   â”œâ”€â”€ main.py                 # Pipeline complet train
â”‚   â”œâ”€â”€ train_model.py          # Training XGBoost + MLflow
â”‚   â””â”€â”€ preprocess.py           # Preprocessing dataset
â”œâ”€â”€ scripts/                    # ğŸ”§ Scripts utilitaires
â”‚   â”œâ”€â”€ create_db.py            # CrÃ©ation base PostgreSQL
â”‚   â”œâ”€â”€ insert_dataset.py       # Insertion donnÃ©es (1470 employÃ©s)
â”‚   â”œâ”€â”€ generate_requirements_hf.sh  # GÃ©nÃ©ration requirements.txt pour HF
â”‚   â””â”€â”€ run_local.sh            # Lancement local dÃ©veloppement
â”œâ”€â”€ docs/                       # ğŸ“š Documentation (5 fichiers minimaux)
â”‚   â”œâ”€â”€ architecture.md         # ğŸ—ï¸ Vue d'ensemble architecture + schÃ©ma BDD
â”‚   â”œâ”€â”€ api_documentation.md    # ğŸ“¡ Endpoints REST + exemples cURL/Python
â”‚   â”œâ”€â”€ database_setup.md       # ğŸ—„ï¸ Setup PostgreSQL + requÃªtes SQL
â”‚   â”œâ”€â”€ tests_report.md         # ğŸ§ª Couverture tests (73%) + rÃ©sultats
â”‚   â””â”€â”€ deployment_guide.md     # ğŸš€ CI/CD + dÃ©ploiement HF Spaces
â”œâ”€â”€ data/                       # ğŸ“Š DonnÃ©es sources (1470 employÃ©s)
â”‚   â”œâ”€â”€ extrait_sondage.csv     # DonnÃ©es satisfaction
â”‚   â”œâ”€â”€ extrait_eval.csv        # DonnÃ©es Ã©valuations
â”‚   â””â”€â”€ extrait_sirh.csv        # DonnÃ©es RH administratives
â”œâ”€â”€ logs/                       # ğŸ“‹ Logs JSON
â”‚   â”œâ”€â”€ api.log                 # Tous les Ã©vÃ©nements
â”‚   â””â”€â”€ error.log               # Erreurs uniquement
â”œâ”€â”€ .github/workflows/          # ğŸ”„ CI/CD
â”‚   â””â”€â”€ ci-cd.yml               # GitHub Actions (lint, test, deploy)
â”œâ”€â”€ pyproject.toml              # ğŸ“¦ Configuration Poetry
â”œâ”€â”€ .env.example                # ğŸ”‘ Template variables environnement
â””â”€â”€ README.md                   # ğŸ“– Ce fichier
```

---

## ğŸ¯ Choix Techniques

### Justifications des Technologies

| Technologie | Alternative | Pourquoi ce choix ? |
|-------------|-------------|---------------------|
| **FastAPI** | Flask, Django REST | âœ… **Typing natif** (validation auto via Pydantic)<br>âœ… **Documentation auto** (Swagger/ReDoc)<br>âœ… **Performance** (async, +200% vs Flask)<br>âœ… **Moderne** (Python 3.12, type hints) |
| **PostgreSQL** | MongoDB, SQLite | âœ… **Relationnel** adaptÃ© aux donnÃ©es structurÃ©es RH<br>âœ… **ACID** pour garantir intÃ©gritÃ©<br>âœ… **ScalabilitÃ©** (index, partitioning)<br>âœ… **Outils matures** (DBeaver, pgAdmin) |
| **XGBoost** | Random Forest, NN | âœ… **Performance** sur donnÃ©es tabulaires<br>âœ… **RÃ©gularisation** intÃ©grÃ©e (Ã©vite overfitting)<br>âœ… **Feature importance** nativement<br>âœ… **Rapide** (parallÃ©lisation) |
| **SMOTE** | Class weights, Under-sampling | âœ… **GÃ©nÃ¨re exemples synthÃ©tiques** (vs duplication)<br>âœ… **Ã‰vite surapprentissage**<br>âœ… **IntÃ©grÃ© imblearn** (CV-safe)<br>âœ… +7% F1 vs class weights |
| **Pydantic** | Marshmallow, Cerberus | âœ… **Validation en C** (via Rust, trÃ¨s rapide)<br>âœ… **Messages d'erreur clairs**<br>âœ… **IntÃ©gration FastAPI** native<br>âœ… **Type safety** compile-time |
| **HuggingFace Hub** | S3, GCP Storage | âœ… **Gratuit** jusqu'Ã  100GB<br>âœ… **Versioning** automatique<br>âœ… **CDN global** (latence faible)<br>âœ… **CommunautÃ©** ML active |
| **Poetry** | pip, conda | âœ… **Lock file** (reproductibilitÃ© garantie)<br>âœ… **Gestion dÃ©pendances** (rÃ©solution conflits)<br>âœ… **Build/Publish** intÃ©grÃ©s<br>âœ… **pyproject.toml** standard moderne |
| **GitHub Actions** | GitLab CI, Jenkins | âœ… **Gratuit** pour repos publics<br>âœ… **IntÃ©gration GitHub** native<br>âœ… **Marketplace** d'actions prÃªtes<br>âœ… **DÃ©ploiement HF** simplifiÃ© |

### Architecture Technique

**Pattern utilisÃ©** : **3-Tier Architecture** (PrÃ©sentation - Logique - DonnÃ©es)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRESENTATION LAYER                        â”‚
â”‚  â€¢ FastAPI (REST API)                                       â”‚
â”‚  â€¢ Gradio (Web UI)                                          â”‚
â”‚  â€¢ Swagger/ReDoc (Documentation interactive)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BUSINESS LAYER                           â”‚
â”‚  â€¢ Validation (Pydantic)                                    â”‚
â”‚  â€¢ Authentification (API Key)                               â”‚
â”‚  â€¢ Rate Limiting (SlowAPI)                                  â”‚
â”‚  â€¢ Preprocessing (Feature Engineering)                      â”‚
â”‚  â€¢ PrÃ©diction (XGBoost Model)                               â”‚
â”‚  â€¢ Logging (JSON Structured)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA LAYER                              â”‚
â”‚  â€¢ PostgreSQL (TraÃ§abilitÃ© prÃ©dictions)                     â”‚
â”‚  â€¢ HuggingFace Hub (ModÃ¨le ML en cache)                     â”‚
â”‚  â€¢ CSV Files (DonnÃ©es sources)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Installation

### PrÃ©requis

| Outil | Version | Installation |
|-------|---------|--------------|
| **Python** | 3.12+ | [python.org](https://www.python.org/downloads/) |
| **Poetry** | 1.7+ | `curl -sSL https://install.python-poetry.org \| python3 -` |
| **PostgreSQL** | 14+ | [postgresql.org](https://www.postgresql.org/download/) ou Docker |
| **Git** | 2.0+ | [git-scm.com](https://git-scm.com/downloads) |

### Ã‰tape 1 : Cloner le Repository



```bash
git clone https://github.com/chaton59/OC_P5.git
cd OC_P5
```

### Ã‰tape 2 : Installer les DÃ©pendances

```bash
# Installation via Poetry (recommandÃ©)
poetry install

# Activer l'environnement virtuel
poetry shell

# OU utiliser pip (fallback)
pip install -r requirements.txt
```

### Ã‰tape 3 : Configuration de l'Environnement

```bash
# Copier le template
cp .env.example .env

# Ã‰diter .env avec vos valeurs
nano .env  # ou vim, code, etc.
```

**Variables Ã  configurer** (`.env`) :

```bash
# === MODE ===
DEBUG=true  # false en production (active auth + rate limiting)

# === API ===
API_KEY=your-secret-api-key-here  # GÃ©nÃ©rer avec: python -c "import secrets; print(secrets.token_urlsafe(32))"
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# === DATABASE (PostgreSQL) ===
DB_HOST=localhost
DB_PORT=5432
DB_NAME=oc_p5_db
DB_USER=ml_user
DB_PASSWORD=your-secure-password  # Ã€ changer !

# === HUGGINGFACE ===
HF_MODEL_REPO=ASI-Engineer/employee-turnover-model
MODEL_FILENAME=model/model.pkl
# HF_TOKEN=hf_xxx  # Optionnel (modÃ¨les publics)
```

### Ã‰tape 4 : Configurer la Base de DonnÃ©es PostgreSQL

#### Option A : Installation locale PostgreSQL

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install postgresql postgresql-contrib

# macOS (via Homebrew)
brew install postgresql@14
brew services start postgresql@14

# Windows : TÃ©lÃ©charger depuis https://www.postgresql.org/download/windows/
```

#### Option B : Docker (recommandÃ© pour dÃ©veloppement)

```bash
# DÃ©marrer PostgreSQL dans un conteneur
docker run --name oc_p5_postgres \
  -e POSTGRES_USER=ml_user \
  -e POSTGRES_PASSWORD=your-password \
  -e POSTGRES_DB=oc_p5_db \
  -p 5432:5432 \
  -d postgres:14
```

#### CrÃ©er les tables

```bash
# CrÃ©er les tables (dataset, ml_logs)
poetry run python scripts/create_db.py

# InsÃ©rer le dataset (1470 employÃ©s)
poetry run python scripts/insert_dataset.py

# VÃ©rifier l'insertion
psql -h localhost -U ml_user -d oc_p5_db -c "SELECT COUNT(*) FROM dataset;"
# RÃ©sultat attendu : 1470
```

**SchÃ©ma de la base de donnÃ©es** :

![SchÃ©ma BDD](docs/schema.png)

ğŸ“– **Guide complet dÃ©butant** : [docs/database_guide.md](docs/database_guide.md)

### Ã‰tape 5 : VÃ©rifier l'Installation

```bash
# Tester que tout fonctionne
poetry run pytest tests/ -v

# RÃ©sultat attendu : 97 tests passÃ©s (ou 86 si skipped dÃ©ployÃ©s)
```

---

## ğŸ”§ Scripts Utilitaires

Le dossier `scripts/` contient les scripts essentiels pour la gestion de la base de donnÃ©es et le dÃ©ploiement. **Minimalisme** : 4 fichiers maximum, code principal dans `src/`, tests dans `tests/`.

### ğŸ—„ï¸ `create_db.py` - CrÃ©ation de la base de donnÃ©es

**RÃ´le** : CrÃ©e la base de donnÃ©es PostgreSQL et les tables nÃ©cessaires (Ã©tape 4 du projet).

```bash
# CrÃ©er les tables (dataset, ml_logs)
poetry run python scripts/create_db.py
```

**Tables crÃ©Ã©es** :
- `dataset` : Stockage des donnÃ©es d'entraÃ®nement (features_json, target)
- `ml_logs` : Logs des prÃ©dictions de l'API (inputs, outputs, timestamps)

### ğŸ“Š `insert_dataset.py` - Insertion du dataset

**RÃ´le** : Charge les 3 fichiers CSV (sondage, eval, sirh), les fusionne et insÃ¨re 1470 employÃ©s dans PostgreSQL (Ã©tape 4 du projet).

```bash
# InsÃ©rer le dataset complet
poetry run python scripts/insert_dataset.py

# VÃ©rifier l'insertion
psql -h localhost -U ml_user -d oc_p5_db -c "SELECT COUNT(*) FROM dataset;"
# RÃ©sultat attendu : 1470
```

**FonctionnalitÃ©s** :
- Fusionne automatiquement les 3 sources de donnÃ©es
- Nettoie les valeurs manquantes (NaN â†’ None)
- Commits par batch de 100 pour performance
- Validation de l'intÃ©gritÃ© des donnÃ©es

### ğŸ“¦ `generate_requirements_hf.sh` - Requirements pour HF Spaces

**RÃ´le** : GÃ©nÃ¨re un fichier `requirements.txt` minimaliste pour dÃ©ploiement sur Hugging Face Spaces (Ã©tape 1 & 2).

```bash
# GÃ©nÃ©rer requirements.txt optimisÃ© pour HF
bash scripts/generate_requirements_hf.sh
```

**Pourquoi nÃ©cessaire ?** HF Spaces nÃ©cessite des dÃ©pendances minimales (pas dev/test). Ce script extrait uniquement les packages essentiels depuis `pyproject.toml`.

### ğŸš€ `run_local.sh` - Lancement local

**RÃ´le** : Script de dÃ©marrage rapide pour dÃ©veloppement local.

```bash
# Lancer l'application en mode dÃ©veloppement
bash scripts/run_local.sh
```

**Actions effectuÃ©es** :
1. Installation des dÃ©pendances (Poetry)
2. VÃ©rification du fichier `.env` (copie `.env.example` si nÃ©cessaire)
3. Lancement de l'interface Gradio sur http://localhost:7860

### ğŸ“ Organisation des Scripts

**Principe de sÃ©paration** :
- **`scripts/`** : Utilitaires BDD et dÃ©ploiement uniquement (4 fichiers max)
- **`src/`** : Code applicatif principal (API, modÃ¨les, preprocessing)
- **`tests/`** : Tests unitaires et fonctionnels (sÃ©parÃ© pour clartÃ©)
- **`.github/workflows/`** : CI/CD (GitHub Actions, pas dans scripts/)

**Justifications** (liÃ©es aux Ã©tapes du projet) :
- âœ… **create_db.py** + **insert_dataset.py** : Ã‰tape 4 (script Python pour crÃ©er BDD + insÃ©rer dataset)
- âœ… **generate_requirements_hf.sh** : Ã‰tape 1 (requirements.txt Ã  la racine) + Ã‰tape 2 (CI/CD, environnements)
- âœ… **run_local.sh** : DÃ©veloppement local (pas obligatoire mais pratique)
- âœ… **Tests dans `tests/`** : Ã‰tape 5 (scripts de tests + rapport couverture)

---

## ğŸš€ Utilisation

### DÃ©marrer l'API Localement

```bash
# Mode dÃ©veloppement (avec auto-reload)
poetry run uvicorn api:app --reload --host 127.0.0.1 --port 8000

# Mode production
poetry run uvicorn api:app --host 0.0.0.0 --port 8000 --workers 4
```

**URLs disponibles** :

| Service | URL | Description |
|---------|-----|-------------|
| **API** | http://localhost:8000 | Endpoint principal |
| **Swagger UI** | http://localhost:8000/docs | Documentation interactive |
| **ReDoc** | http://localhost:8000/redoc | Documentation alternative |
| **Health Check** | http://localhost:8000/health | Statut de l'API |
| **Gradio UI** | http://localhost:8000/ui | Interface web (si activÃ©e) |

### Exemples d'Appels API

#### 1. Health Check

```bash
curl http://localhost:8000/health
```

**RÃ©ponse** :
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_type": "Pipeline",
  "version": "3.2.1"
}
```

#### 2. PrÃ©diction Unitaire (JSON)

```bash
# Sans authentification (DEBUG=true)
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "age": 35,
    "genre": "M",
    "revenu_mensuel": 4500.0,
    "satisfaction_employee_environnement": 3,
    ...
  }'

# Avec authentification (DEBUG=false)
curl -X POST http://localhost:8000/predict \
  -H "X-API-Key: your-secret-key" \
  -H "Content-Type: application/json" \
  -d @employee.json
```

**RÃ©ponse** :
```json
{
  "prediction": 0,
  "probability_0": 0.85,
  "probability_1": 0.15,
  "risk_level": "Low"
}
```

#### 3. PrÃ©diction Batch (CSV)

```bash
curl -X POST http://localhost:8000/predict/batch \
  -H "X-API-Key: your-key" \
  -F "sondage_file=@data/extrait_sondage.csv" \
  -F "eval_file=@data/extrait_eval.csv" \
  -F "sirh_file=@data/extrait_sirh.csv"
```

**RÃ©ponse** :
```json
{
  "total_employees": 1470,
  "predictions": [...],
  "summary": {
    "total_stay": 1169,
    "total_leave": 301,
    "high_risk_count": 222
  }
}
```

### Utilisation Python (SDK)

```python
import requests

# Configuration
API_URL = "http://localhost:8000/predict"
API_KEY = "your-secret-key"

# DonnÃ©es employÃ©
employee = {
    "age": 28,
    "genre": "F",
    "revenu_mensuel": 3200.0,
    "departement": "Consulting",
    # ... (tous les 29 champs requis)
}

# Appel API
response = requests.post(
    API_URL,
    headers={"X-API-Key": API_KEY, "Content-Type": "application/json"},
    json=employee
)

# RÃ©sultat
if response.status_code == 200:
    result = response.json()
    print(f"Risque de dÃ©part: {result['probability_1']:.0%}")
    print(f"Niveau: {result['risk_level']}")
```

ğŸ“š **Documentation API** : [docs/api_documentation.md](docs/api_documentation.md)

---

## ğŸŒ DÃ©ploiement

### Environnements Disponibles

| Environnement | Branche Git | URL HuggingFace Spaces | Statut |
|---------------|-------------|------------------------|--------|
| **Production** | `main` | https://asi-engineer-oc-p5.hf.space | âœ… Live |
| **DÃ©veloppement** | `dev` | https://asi-engineer-oc-p5-dev.hf.space | ğŸš§ Testing |

### ğŸ¤— HuggingFace Spaces Integration

L'API est dÃ©ployÃ©e sur **HuggingFace Spaces** avec une interface interactive Gradio.

#### MÃ©tadonnÃ©es HF Spaces

Le fichier `README_HF.md` est fusionnÃ© dans cette section pour HF Spaces:

```yaml
title: Employee Turnover Prediction API
emoji: ğŸ‘”
colorFrom: blue
colorTo: purple
sdk: gradio
pinned: true
license: mit
app_port: 7860
```

#### Endpoints HF Spaces

| Endpoint | Description | AccÃ¨s |
|----------|-------------|-------|
| `/docs` | Documentation interactive Swagger | Public |
| `/health` | Status de l'API | Public |
| `/ui` | Interface Gradio interactive | Public |
| `/predict` | PrÃ©diction unitaire (JSON, contraintes rÃ©elles) | API Key requis |
| `/predict/batch` | PrÃ©diction batch (3 fichiers CSV bruts) | API Key requis |

#### Exemple Utilisation HF Spaces

**PrÃ©diction unitaire** (avec toutes contraintes appliquÃ©es):
```bash
curl -X POST https://asi-engineer-oc-p5.hf.space/predict \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-key" \
  -d '{
    "nombre_participation_pee": 0,
    "nb_formations_suivies": 2,
    "nombre_employee_sous_responsabilite": 1,
    ...
  }'
```

**PrÃ©diction batch** (3 fichiers CSV):
```bash
curl -X POST https://asi-engineer-oc-p5.hf.space/predict/batch \
  -H "X-API-Key: your-key" \
  -F "sondage_file=@extrait_sondage.csv" \
  -F "eval_file=@extrait_eval.csv" \
  -F "sirh_file=@extrait_sirh.csv"
```

**RÃ©ponse batch**:
```json
{
  "total_employees": 1470,
  "predictions": [...],
  "summary": {
    "total_stay": 1169,
    "total_leave": 301,
    "high_risk_count": 222
  }
}
```

### Pipeline CI/CD (GitHub Actions)

Le workflow `.github/workflows/ci-cd.yml` s'exÃ©cute automatiquement Ã  chaque push :

```mermaid
graph LR
    A[Push Code] --> B[Lint: Black + Flake8]
    B --> C[Tests: pytest 97 tests]
    C --> D[Test API Server]
    D --> E{Branche?}
    E -->|dev| F[Deploy HF Dev]
    E -->|main| G[Deploy HF Prod]
```

**Jobs du pipeline** :

1. **Lint** (~30s) : Black (formatage) + Flake8 (qualitÃ©)
2. **Tests** (~3min) : pytest avec couverture (70%)
3. **Test API Server** (~2min) : DÃ©marrage uvicorn + tests `/health` et `/predict`
4. **Deploy** : DÃ©ploiement automatique sur HuggingFace Spaces

âš¡ **Temps total** : ~5-7 minutes (< 10min requis)

### DÃ©ploiement Manuel sur HuggingFace Spaces

#### PrÃ©requis

```bash
# Installer la CLI HuggingFace
pip install huggingface_hub

# Se connecter
huggingface-cli login
# Entrer votre token (crÃ©er sur https://huggingface.co/settings/tokens)
```

#### Pousser vers HF Spaces

```bash
# 1. Ajouter le remote HF
git remote add space https://huggingface.co/spaces/ASI-Engineer/oc_p5

# 2. Push vers HF
git push space main

# 3. VÃ©rifier le dÃ©ploiement
# Visiter https://huggingface.co/spaces/ASI-Engineer/oc_p5
```

#### Configuration des Secrets HF Spaces

Dans les settings du Space HuggingFace, ajouter :

| Variable | Valeur | Description |
|----------|--------|-------------|
| `API_KEY` | `votre-clÃ©-sÃ©curisÃ©e` | Authentification API |
| `DEBUG` | `false` | Mode production |
| `LOG_LEVEL` | `INFO` | Niveau de logs |

### DÃ©ploiement Docker (Alternative)

```bash
# Build de l'image
docker build -t employee-turnover-api .

# Run du conteneur
docker run -d \
  -p 8000:8000 \
  -e API_KEY=your-key \
  -e DEBUG=false \
  --name turnover-api \
  employee-turnover-api

# VÃ©rifier
curl http://localhost:8000/health
```

ğŸ“– **Guide complet** : [docs/deployment_guide.md](docs/deployment_guide.md)

---

## ğŸ”„ Mise Ã  Jour

### Mise Ã  Jour du Code

```bash
# 1. RÃ©cupÃ©rer les derniÃ¨res modifications
git pull origin main

# 2. Mettre Ã  jour les dÃ©pendances
poetry update

# 3. Appliquer les migrations DB (si nÃ©cessaire)
poetry run python scripts/migrate_db.py

# 4. Relancer l'API
poetry run uvicorn api:app --reload
```

### RÃ©-entraÃ®nement du ModÃ¨le

**FrÃ©quence recommandÃ©e** : Tous les 3 mois (ou si drift dÃ©tectÃ©)

```bash
# 1. PrÃ©parer les nouvelles donnÃ©es
cp /path/to/new/data/*.csv data/

# 2. Lancer l'entraÃ®nement (avec MLflow tracking)
cd ml_model
poetry run python main.py

# 3. Comparer les performances
poetry run mlflow ui
# Ouvrir http://localhost:5000

# 4. Si F1 Score â‰¥ 0.83, exporter le modÃ¨le
poetry run python -c "
import joblib
import mlflow

client = mlflow.tracking.MlflowClient()
model_version = client.get_latest_versions('XGBoost_Employee_Turnover')[0]
model = mlflow.sklearn.load_model(model_version.source)
joblib.dump(model, 'model.pkl')
"

# 5. Uploader vers HuggingFace Hub
poetry run python -c "
from huggingface_hub import HfApi

api = HfApi()
api.upload_file(
    path_or_fileobj='model.pkl',
    path_in_repo='model/model.pkl',
    repo_id='ASI-Engineer/employee-turnover-model',
    commit_message='Update model v1.1 - F1=0.87'
)
"

# 6. CrÃ©er un tag Git pour versioning
git tag -a model-v1.1 -m "Model update: F1=0.87, Recall=0.89"
git push origin model-v1.1
```

### Monitoring du Drift

```python
# Script de dÃ©tection de drift (Ã  automatiser mensuellement)
import pandas as pd
from scipy.stats import ks_2samp

train_data = pd.read_csv('data/extrait_sirh.csv')
new_data = pd.read_csv('logs/recent_predictions.csv')

for col in ['age', 'revenu_mensuel', 'annees_dans_l_entreprise']:
    statistic, pvalue = ks_2samp(train_data[col], new_data[col])
    if pvalue < 0.05:
        print(f'âš ï¸ DRIFT dÃ©tectÃ© sur {col} (p={pvalue:.4f})')
        # â†’ DÃ©clencher rÃ©-entraÃ®nement
```

ğŸ“– **DÃ©tails modÃ¨le & maintenance** : inclus dans [docs/architecture.md](docs/architecture.md) (section Pipeline ML) et [docs/tests_report.md](docs/tests_report.md) pour les vÃ©rifications automatiques.

---



## âœ… Tests

### Suite de Tests ComplÃ¨te

```bash
# Lancer tous les tests
poetry run pytest tests/ -v

# Avec rapport de couverture
poetry run pytest tests/ --cov=. --cov-report=term-missing

# Avec rapport HTML
poetry run pytest tests/ --cov=. --cov-report=html
open htmlcov/index.html
```

### MÃ©triques

| MÃ©trique | Valeur | DÃ©tail |
|----------|--------|--------|
| **Tests** | 97 | 86 passÃ©s, 11 skippÃ©s (dÃ©ploiement) |
| **Couverture** | 70.26% | Objectif : â‰¥ 70% |
| **DurÃ©e** | ~4s | Temps d'exÃ©cution total |
| **Fichiers** | 9 | test_api_*.py, test_database.py, test_model.py |

### CatÃ©gories de Tests

- âœ… **Authentification** (11 tests) : API Key, headers, rate limiting
- âœ… **Health Check** (6 tests) : Status, modÃ¨le chargÃ©, versionning
- âœ… **PrÃ©diction** (9 tests) : Endpoint `/predict`, probabilitÃ©s, cohÃ©rence
- âœ… **Validation** (15 tests) : Pydantic, types, Ã©numÃ©rations, limites
- âœ… **Database** (7 tests) : Connexion, CRUD, intÃ©gritÃ©
- âœ… **Fonctionnel** (19 tests) : End-to-end, performance, erreurs
- âœ… **ModÃ¨le ML** (23 tests) : Chargement HF, preprocessing, prÃ©dictions
- âœ… **API DÃ©ployÃ©e** (7 tests skippÃ©s) : Tests sur HF Spaces

ğŸ“Š **DÃ©tail de couverture** :

| Module | Couverture | Lignes | Manquantes |
|--------|------------|--------|------------|
| `src/config.py` | 100% | 20 | 0 |
| `src/schemas.py` | 100% | 100 | 0 |
| `src/rate_limit.py` | 100% | 10 | 0 |
| `db_models.py` | 100% | 14 | 0 |
| `src/logger.py` | 90.32% | 62 | 6 |
| `src/preprocessing.py` | 76.36% | 55 | 13 |
| `api.py` | 55.41% | 157 | 70 |

---

## ğŸ“š Documentation


### Navigation dans le dossier `docs/`

Documentation **minimaliste et structurÃ©e** en **5 fichiers** couvrant tous les aspects du projet :

| Document | Description | Ã‰tapes OC |
|----------|-------------|-----------|
| [ğŸ—ï¸ architecture.md](docs/architecture.md) | Vue d'ensemble du projet, schÃ©ma architecture, diagramme BDD (PlantUML), flux de donnÃ©es | Ã‰tape 4, 6 |
| [ğŸ“¡ api_documentation.md](docs/api_documentation.md) | Documentation API REST : endpoints, schÃ©mas Pydantic, exemples cURL/Python, codes erreurs | Ã‰tape 3, 6 |
| [ğŸ—„ï¸ database_setup.md](docs/database_setup.md) | Configuration PostgreSQL, scripts crÃ©ation BDD, requÃªtes SQL utiles, sauvegarde/restauration | Ã‰tape 4 |
| [ğŸ§ª tests_report.md](docs/tests_report.md) | Rapport de couverture (73%), dÃ©tail des 48 tests unitaires/fonctionnels, commandes pytest | Ã‰tape 5 |
| [ğŸš€ deployment_guide.md](docs/deployment_guide.md) | CI/CD GitHub Actions, dÃ©ploiement HuggingFace Spaces, gestion secrets, monitoring | Ã‰tape 2, 6 |

**Choix de conception** : Documentation concise (1-2 pages par fichier) privilÃ©giant la **clartÃ©** et **l'actionnable** sur l'exhaustivitÃ©.

**Documentation interactive** :
- ğŸŒ **Swagger UI** : http://localhost:8000/docs
- ğŸ“˜ **ReDoc** : http://localhost:8000/redoc

---

## ğŸ“¦ DÃ©pendances Principales

| Package | Version | RÃ´le |
|---------|---------|------|
| **FastAPI** | 0.115.14 | Framework API REST |
| **Pydantic** | 2.12.5 | Validation donnÃ©es |
| **XGBoost** | 2.1.3 | ModÃ¨le ML |
| **imbalanced-learn** | 0.12.0 | SMOTE (rÃ©Ã©quilibrage) |
| **SQLAlchemy** | 2.0.23 | ORM PostgreSQL |
| **psycopg2-binary** | 2.9.9 | Driver PostgreSQL |
| **SlowAPI** | 0.1.9 | Rate limiting |
| **python-json-logger** | 4.0.0 | Logs structurÃ©s |
| **pytest** | 9.0.2 | Tests unitaires |
| **MLflow** | 2.9.2 | Tracking expÃ©riences ML |
| **Gradio** | 4.13.0 | Interface web |

Voir [pyproject.toml](pyproject.toml) pour la liste complÃ¨te.

---



## ğŸ”„ Changelog

### v3.3.0 (Janvier 2026)
- ğŸ“š Documentation minimaliste consolidÃ©e en 5 fichiers (architecture, API, BDD, tests, dÃ©ploiement)
- ğŸ§¹ Suppression des documents redondants et archives pour allÃ©ger la page HF
- ğŸ“ README simplifiÃ© avec navigation claire vers la nouvelle doc

### v3.2.1 (Janvier 2026)
- ğŸ›ï¸ Sliders Gradio et schÃ©mas Pydantic alignÃ©s sur les min/max rÃ©els des donnÃ©es d'entraÃ®nement
- ğŸ“¦ Endpoint batch CSV (3 fichiers bruts)
- ğŸ”‘ Authentification API Key (prod)
- ğŸ”§ Correction preprocessing (scaling, ordre des colonnes)
- ğŸ“ Documentation mise Ã  jour (API, modÃ¨le)

### v2.2.0 (27 DÃ©cembre 2025)
- ğŸ“¦ Nouvel endpoint `/predict/batch` pour traitement CSV direct
- ğŸ”§ Fix preprocessing : ajout du scaling des features
- ğŸ”§ Fix preprocessing : correction de l'ordre des colonnes
- ğŸ“Š AmÃ©lioration prÃ©cision des prÃ©dictions (~90%)

### v2.1.0 (26 DÃ©cembre 2025)
- âœ¨ SystÃ¨me de logging structurÃ© JSON
- ğŸ›¡ï¸ Rate limiting avec SlowAPI
- âš¡ AmÃ©lioration gestion d'erreurs
- ğŸ“Š Monitoring des performances

### v2.0.0 (26 DÃ©cembre 2025)
- âœ… Suite de tests complÃ¨te (97 tests)
- ğŸ” Authentification API Key
- ğŸ“Š 70% de couverture de code

---

## ğŸ‘¥ Auteurs

**DÃ©veloppeur** : Valentin (chaton59)  
**Projet** : OpenClassrooms P5 - DÃ©ployez votre modÃ¨le de Machine Learning  
**Repo GitHub** : [github.com/chaton59/OC_P5](https://github.com/chaton59/OC_P5)  
**HuggingFace** : [ASI-Engineer](https://huggingface.co/ASI-Engineer)

---

## ğŸ“„ Licence

Ce projet est dÃ©veloppÃ© dans un cadre pÃ©dagogique (OpenClassrooms).  
Les donnÃ©es utilisÃ©es sont fictives.

---

## ğŸ¤ Contributing

Les contributions sont bienvenues ! Pour contribuer :

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

---

## ğŸ“ Contact & Support

- **Issues GitHub** : [github.com/chaton59/OC_P5/issues](https://github.com/chaton59/OC_P5/issues)
- **Discussions** : [github.com/chaton59/OC_P5/discussions](https://github.com/chaton59/OC_P5/discussions)
- **Email** : Voir profil GitHub

---

## ğŸ™ Remerciements

- **OpenClassrooms** pour le parcours Data Scientist
- **HuggingFace** pour l'hÃ©bergement gratuit
- **FastAPI** pour le framework moderne
- **CommunautÃ© Python ML** pour les bibliothÃ¨ques open-source

---

<div align="center">

**â­ Si ce projet vous a aidÃ©, n'hÃ©sitez pas Ã  lui donner une Ã©toile sur GitHub ! â­**

Made with â¤ï¸ by [chaton59](https://github.com/chaton59)

</div>

